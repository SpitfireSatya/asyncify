{
  "0": [
    {
      "filename": "/home/osboxes/deepforge/src/routers/InteractiveCompute/job-files/index.js",
      "startLine": 6,
      "endLine": 6,
      "before": "fs.readFileSync(path.join(__dirname, 'start.js'), 'utf8')",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait fs.promises.readFile(path.join(__dirname, 'start.js'), 'utf8')"
    }
  ],
  "1": [
    {
      "filename": "/home/osboxes/deepforge/src/routers/InteractiveCompute/job-files/index.js",
      "startLine": 9,
      "endLine": 9,
      "before": "fs.readFileSync(path.join(interactiveDir, 'message.js'), 'utf8')",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait fs.promises.readFile(path.join(interactiveDir, 'message.js'), 'utf8')"
    }
  ],
  "2": [
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 122,
      "endLine": 122,
      "before": "function (docName) {\n  var p = docName.toLowerCase().split(\".\");\n  if (!p[1]) return;\n  var modeName;\n  if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n    \"txt\": \"text\",\n    cpp: \"c_cpp\"\n  }[p[1]];\n  if (names && names.length && names.indexOf(modeName) == -1) return;\n  var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n  try {\n    var oldOutput = require(outputPath);\n  } catch (e) {}\n\n  if (oldOutput && !force) {\n    var oldText = oldOutput.map(function (x) {\n      if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n      return x.slice(1).map(function (tok) {\n        return tok[1];\n      }).join(\"\");\n    }).join(\"\\n\");\n  }\n\n  var filePath = \"text_\" + modeName + \".txt\";\n\n  if (specialDocs.indexOf(filePath) !== -1) {\n    filePath = cwd + filePath;\n  } else {\n    filePath = docRoot + \"/\" + docName; // oldText = \"\";\n  }\n\n  var text = oldText || fs.readFileSync(filePath, \"utf8\");\n\n  try {\n    var Mode = require(\"../\" + modeName).Mode;\n  } catch (e) {\n    console.warn(\"Can't load mode :\" + modeName, p, e);\n    return;\n  }\n\n  console.log(modeName);\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n    var data = tokenizer.getLineTokens(line, state);\n    var tmp = [];\n    tmp.push(JSON.stringify(data.state));\n    var tokenizedLine = \"\";\n    data.tokens.forEach(function (x) {\n      tokenizedLine += x.value;\n      tmp.push(JSON.stringify([x.type, x.value]));\n    });\n    if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n    state = data.state;\n    return tmp.join(\",\\n  \");\n  });\n  var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n  if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n  fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n}",
      "after": "async function (docName) {\n  var p = docName.toLowerCase().split(\".\");\n  if (!p[1]) return;\n  var modeName;\n  if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n    \"txt\": \"text\",\n    cpp: \"c_cpp\"\n  }[p[1]];\n  if (names && names.length && names.indexOf(modeName) == -1) return;\n  var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n  try {\n    var oldOutput = require(outputPath);\n  } catch (e) {}\n\n  if (oldOutput && !force) {\n    var oldText = oldOutput.map(function (x) {\n      if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n      return x.slice(1).map(function (tok) {\n        return tok[1];\n      }).join(\"\");\n    }).join(\"\\n\");\n  }\n\n  var filePath = \"text_\" + modeName + \".txt\";\n\n  if (specialDocs.indexOf(filePath) !== -1) {\n    filePath = cwd + filePath;\n  } else {\n    filePath = docRoot + \"/\" + docName; // oldText = \"\";\n  }\n\n  var text = oldText || (await fs.promises.readFile(filePath, \"utf8\"));\n\n  try {\n    var Mode = require(\"../\" + modeName).Mode;\n  } catch (e) {\n    console.warn(\"Can't load mode :\" + modeName, p, e);\n    return;\n  }\n\n  console.log(modeName);\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n    var data = tokenizer.getLineTokens(line, state);\n    var tmp = [];\n    tmp.push(JSON.stringify(data.state));\n    var tokenizedLine = \"\";\n    data.tokens.forEach(function (x) {\n      tokenizedLine += x.value;\n      tmp.push(JSON.stringify([x.type, x.value]));\n    });\n    if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n    state = data.state;\n    return tmp.join(\",\\n  \");\n  });\n  var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n  if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n  fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 86,
      "endLine": 155,
      "before": "function generateTestData(names, force) {\n  var docRoot = root + \"/demo/kitchen-sink/docs\";\n  var docs = fs.readdirSync(docRoot);\n  var specialDocs = fs.readdirSync(cwd);\n  var modes = modeList(); // console.log(\"Docs:\", docs);\n  // console.log(\"Modes:\", modes);\n\n  docs.forEach(function (docName) {\n    var p = docName.toLowerCase().split(\".\");\n    if (!p[1]) return;\n    var modeName;\n    if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n      \"txt\": \"text\",\n      cpp: \"c_cpp\"\n    }[p[1]];\n    if (names && names.length && names.indexOf(modeName) == -1) return;\n    var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n    try {\n      var oldOutput = require(outputPath);\n    } catch (e) {}\n\n    if (oldOutput && !force) {\n      var oldText = oldOutput.map(function (x) {\n        if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n        return x.slice(1).map(function (tok) {\n          return tok[1];\n        }).join(\"\");\n      }).join(\"\\n\");\n    }\n\n    var filePath = \"text_\" + modeName + \".txt\";\n\n    if (specialDocs.indexOf(filePath) !== -1) {\n      filePath = cwd + filePath;\n    } else {\n      filePath = docRoot + \"/\" + docName; // oldText = \"\";\n    }\n\n    var text = oldText || fs.readFileSync(filePath, \"utf8\");\n\n    try {\n      var Mode = require(\"../\" + modeName).Mode;\n    } catch (e) {\n      console.warn(\"Can't load mode :\" + modeName, p, e);\n      return;\n    }\n\n    console.log(modeName);\n    var tokenizer = new Mode().getTokenizer();\n    var state = \"start\";\n    var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n      var data = tokenizer.getLineTokens(line, state);\n      var tmp = [];\n      tmp.push(JSON.stringify(data.state));\n      var tokenizedLine = \"\";\n      data.tokens.forEach(function (x) {\n        tokenizedLine += x.value;\n        tmp.push(JSON.stringify([x.type, x.value]));\n      });\n      if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n      state = data.state;\n      return tmp.join(\",\\n  \");\n    });\n    var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n    if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n    fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n  });\n}",
      "after": "async function generateTestData(names, force) {\n  var docRoot = root + \"/demo/kitchen-sink/docs\";\n  var docs = fs.readdirSync(docRoot);\n  var specialDocs = fs.readdirSync(cwd);\n  var modes = modeList(); // console.log(\"Docs:\", docs);\n  // console.log(\"Modes:\", modes);\n\n  await docs.forEach(async function (docName) {\n    var p = docName.toLowerCase().split(\".\");\n    if (!p[1]) return;\n    var modeName;\n    if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n      \"txt\": \"text\",\n      cpp: \"c_cpp\"\n    }[p[1]];\n    if (names && names.length && names.indexOf(modeName) == -1) return;\n    var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n    try {\n      var oldOutput = require(outputPath);\n    } catch (e) {}\n\n    if (oldOutput && !force) {\n      var oldText = oldOutput.map(function (x) {\n        if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n        return x.slice(1).map(function (tok) {\n          return tok[1];\n        }).join(\"\");\n      }).join(\"\\n\");\n    }\n\n    var filePath = \"text_\" + modeName + \".txt\";\n\n    if (specialDocs.indexOf(filePath) !== -1) {\n      filePath = cwd + filePath;\n    } else {\n      filePath = docRoot + \"/\" + docName; // oldText = \"\";\n    }\n\n    var text = oldText || (await fs.promises.readFile(filePath, \"utf8\"));\n\n    try {\n      var Mode = require(\"../\" + modeName).Mode;\n    } catch (e) {\n      console.warn(\"Can't load mode :\" + modeName, p, e);\n      return;\n    }\n\n    console.log(modeName);\n    var tokenizer = new Mode().getTokenizer();\n    var state = \"start\";\n    var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n      var data = tokenizer.getLineTokens(line, state);\n      var tmp = [];\n      tmp.push(JSON.stringify(data.state));\n      var tokenizedLine = \"\";\n      data.tokens.forEach(function (x) {\n        tokenizedLine += x.value;\n        tmp.push(JSON.stringify([x.type, x.value]));\n      });\n      if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n      state = data.state;\n      return tmp.join(\",\\n  \");\n    });\n    var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n    if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n    fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n  });\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 244,
      "endLine": 244,
      "before": "generateTestData(process.argv.splice(3))",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait generateTestData(process.argv.splice(3))"
    }
  ],
  "3": [
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 154,
      "endLine": 154,
      "before": "function (docName) {\n  var p = docName.toLowerCase().split(\".\");\n  if (!p[1]) return;\n  var modeName;\n  if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n    \"txt\": \"text\",\n    cpp: \"c_cpp\"\n  }[p[1]];\n  if (names && names.length && names.indexOf(modeName) == -1) return;\n  var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n  try {\n    var oldOutput = require(outputPath);\n  } catch (e) {}\n\n  if (oldOutput && !force) {\n    var oldText = oldOutput.map(function (x) {\n      if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n      return x.slice(1).map(function (tok) {\n        return tok[1];\n      }).join(\"\");\n    }).join(\"\\n\");\n  }\n\n  var filePath = \"text_\" + modeName + \".txt\";\n\n  if (specialDocs.indexOf(filePath) !== -1) {\n    filePath = cwd + filePath;\n  } else {\n    filePath = docRoot + \"/\" + docName; // oldText = \"\";\n  }\n\n  var text = oldText || fs.readFileSync(filePath, \"utf8\");\n\n  try {\n    var Mode = require(\"../\" + modeName).Mode;\n  } catch (e) {\n    console.warn(\"Can't load mode :\" + modeName, p, e);\n    return;\n  }\n\n  console.log(modeName);\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n    var data = tokenizer.getLineTokens(line, state);\n    var tmp = [];\n    tmp.push(JSON.stringify(data.state));\n    var tokenizedLine = \"\";\n    data.tokens.forEach(function (x) {\n      tokenizedLine += x.value;\n      tmp.push(JSON.stringify([x.type, x.value]));\n    });\n    if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n    state = data.state;\n    return tmp.join(\",\\n  \");\n  });\n  var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n  if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n  fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n}",
      "after": "async function (docName) {\n  var p = docName.toLowerCase().split(\".\");\n  if (!p[1]) return;\n  var modeName;\n  if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n    \"txt\": \"text\",\n    cpp: \"c_cpp\"\n  }[p[1]];\n  if (names && names.length && names.indexOf(modeName) == -1) return;\n  var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n  try {\n    var oldOutput = require(outputPath);\n  } catch (e) {}\n\n  if (oldOutput && !force) {\n    var oldText = oldOutput.map(function (x) {\n      if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n      return x.slice(1).map(function (tok) {\n        return tok[1];\n      }).join(\"\");\n    }).join(\"\\n\");\n  }\n\n  var filePath = \"text_\" + modeName + \".txt\";\n\n  if (specialDocs.indexOf(filePath) !== -1) {\n    filePath = cwd + filePath;\n  } else {\n    filePath = docRoot + \"/\" + docName; // oldText = \"\";\n  }\n\n  var text = oldText || (await fs.promises.readFile(filePath, \"utf8\"));\n\n  try {\n    var Mode = require(\"../\" + modeName).Mode;\n  } catch (e) {\n    console.warn(\"Can't load mode :\" + modeName, p, e);\n    return;\n  }\n\n  console.log(modeName);\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n    var data = tokenizer.getLineTokens(line, state);\n    var tmp = [];\n    tmp.push(JSON.stringify(data.state));\n    var tokenizedLine = \"\";\n    data.tokens.forEach(function (x) {\n      tokenizedLine += x.value;\n      tmp.push(JSON.stringify([x.type, x.value]));\n    });\n    if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n    state = data.state;\n    return tmp.join(\",\\n  \");\n  });\n  var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n  if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n  await fs.promises.writeFile(outputPath, jsonStr, \"utf8\");\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 86,
      "endLine": 155,
      "before": "function generateTestData(names, force) {\n  var docRoot = root + \"/demo/kitchen-sink/docs\";\n  var docs = fs.readdirSync(docRoot);\n  var specialDocs = fs.readdirSync(cwd);\n  var modes = modeList(); // console.log(\"Docs:\", docs);\n  // console.log(\"Modes:\", modes);\n\n  docs.forEach(function (docName) {\n    var p = docName.toLowerCase().split(\".\");\n    if (!p[1]) return;\n    var modeName;\n    if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n      \"txt\": \"text\",\n      cpp: \"c_cpp\"\n    }[p[1]];\n    if (names && names.length && names.indexOf(modeName) == -1) return;\n    var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n    try {\n      var oldOutput = require(outputPath);\n    } catch (e) {}\n\n    if (oldOutput && !force) {\n      var oldText = oldOutput.map(function (x) {\n        if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n        return x.slice(1).map(function (tok) {\n          return tok[1];\n        }).join(\"\");\n      }).join(\"\\n\");\n    }\n\n    var filePath = \"text_\" + modeName + \".txt\";\n\n    if (specialDocs.indexOf(filePath) !== -1) {\n      filePath = cwd + filePath;\n    } else {\n      filePath = docRoot + \"/\" + docName; // oldText = \"\";\n    }\n\n    var text = oldText || fs.readFileSync(filePath, \"utf8\");\n\n    try {\n      var Mode = require(\"../\" + modeName).Mode;\n    } catch (e) {\n      console.warn(\"Can't load mode :\" + modeName, p, e);\n      return;\n    }\n\n    console.log(modeName);\n    var tokenizer = new Mode().getTokenizer();\n    var state = \"start\";\n    var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n      var data = tokenizer.getLineTokens(line, state);\n      var tmp = [];\n      tmp.push(JSON.stringify(data.state));\n      var tokenizedLine = \"\";\n      data.tokens.forEach(function (x) {\n        tokenizedLine += x.value;\n        tmp.push(JSON.stringify([x.type, x.value]));\n      });\n      if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n      state = data.state;\n      return tmp.join(\",\\n  \");\n    });\n    var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n    if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n    fs.writeFileSync(outputPath, jsonStr, \"utf8\");\n  });\n}",
      "after": "async function generateTestData(names, force) {\n  var docRoot = root + \"/demo/kitchen-sink/docs\";\n  var docs = fs.readdirSync(docRoot);\n  var specialDocs = fs.readdirSync(cwd);\n  var modes = modeList(); // console.log(\"Docs:\", docs);\n  // console.log(\"Modes:\", modes);\n\n  await docs.forEach(async function (docName) {\n    var p = docName.toLowerCase().split(\".\");\n    if (!p[1]) return;\n    var modeName;\n    if (modes.indexOf(p[0]) != -1) modeName = p[0];else if (modes.indexOf(p[1]) != -1) modeName = p[1];else modeName = {\n      \"txt\": \"text\",\n      cpp: \"c_cpp\"\n    }[p[1]];\n    if (names && names.length && names.indexOf(modeName) == -1) return;\n    var outputPath = cwd + \"tokens_\" + modeName + \".json\";\n\n    try {\n      var oldOutput = require(outputPath);\n    } catch (e) {}\n\n    if (oldOutput && !force) {\n      var oldText = oldOutput.map(function (x) {\n        if (x.length > 1 && typeof x[x.length - 1] == \"string\") return x[x.length - 1];\n        return x.slice(1).map(function (tok) {\n          return tok[1];\n        }).join(\"\");\n      }).join(\"\\n\");\n    }\n\n    var filePath = \"text_\" + modeName + \".txt\";\n\n    if (specialDocs.indexOf(filePath) !== -1) {\n      filePath = cwd + filePath;\n    } else {\n      filePath = docRoot + \"/\" + docName; // oldText = \"\";\n    }\n\n    var text = oldText || (await fs.promises.readFile(filePath, \"utf8\"));\n\n    try {\n      var Mode = require(\"../\" + modeName).Mode;\n    } catch (e) {\n      console.warn(\"Can't load mode :\" + modeName, p, e);\n      return;\n    }\n\n    console.log(modeName);\n    var tokenizer = new Mode().getTokenizer();\n    var state = \"start\";\n    var data = text.split(/\\r\\n|\\r|\\n/).map(function (line) {\n      var data = tokenizer.getLineTokens(line, state);\n      var tmp = [];\n      tmp.push(JSON.stringify(data.state));\n      var tokenizedLine = \"\";\n      data.tokens.forEach(function (x) {\n        tokenizedLine += x.value;\n        tmp.push(JSON.stringify([x.type, x.value]));\n      });\n      if (tokenizedLine != line) tmp.push(JSON.stringify(line));\n      state = data.state;\n      return tmp.join(\",\\n  \");\n    });\n    var jsonStr = \"[[\\n   \" + data.join(\"\\n],[\\n   \") + \"\\n]]\";\n    if (oldOutput && JSON.stringify(JSON.parse(jsonStr)) == JSON.stringify(oldOutput)) return;\n    await fs.promises.writeFile(outputPath, jsonStr, \"utf8\");\n  });\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 244,
      "endLine": 244,
      "before": "generateTestData(process.argv.splice(3))",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait generateTestData(process.argv.splice(3))"
    }
  ],
  "4": [
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 171,
      "endLine": 171,
      "before": "function testMode(modeName, i) {\n  console.log(padNumber(i + 1, 3) + \") testing: \\u001b[33m\" + modeName + \"\\u001b[0m\");\n  var text = fs.readFileSync(cwd + \"tokens_\" + modeName + \".json\", \"utf8\");\n  var data = JSON.parse(text);\n\n  var Mode = require(\"../\" + modeName).Mode;\n\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  data.forEach(function (lineData) {\n    lineData.values = [];\n    lineData.types = [];\n    lineData.state = lineData.shift();\n    var line = null;\n    if (typeof lineData[lineData.length - 1] == \"string\") line = lineData.pop();\n    lineData.forEach(function (x) {\n      lineData.types.push(x[0]);\n      lineData.values.push(x[1]);\n    });\n    if (typeof line != \"string\") line = lineData.values.join(\"\");\n    var tokens = tokenizer.getLineTokens(line, state);\n    var values = tokens.tokens.map(function (x) {\n      return x.value;\n    });\n    var types = tokens.tokens.map(function (x) {\n      return x.type;\n    });\n    var err = testEqual([JSON.stringify(lineData.state), JSON.stringify(tokens.state), lineData.types, types, lineData.values, values]);\n\n    if (err) {\n      console.log(line);\n      throw \"error\";\n    }\n\n    state = tokens.state;\n  });\n}",
      "after": "async function testMode(modeName, i) {\n  console.log(padNumber(i + 1, 3) + \") testing: \\u001b[33m\" + modeName + \"\\u001b[0m\");\n  var text = await fs.promises.readFile(cwd + \"tokens_\" + modeName + \".json\", \"utf8\");\n  var data = JSON.parse(text);\n\n  var Mode = require(\"../\" + modeName).Mode;\n\n  var tokenizer = new Mode().getTokenizer();\n  var state = \"start\";\n  data.forEach(function (lineData) {\n    lineData.values = [];\n    lineData.types = [];\n    lineData.state = lineData.shift();\n    var line = null;\n    if (typeof lineData[lineData.length - 1] == \"string\") line = lineData.pop();\n    lineData.forEach(function (x) {\n      lineData.types.push(x[0]);\n      lineData.values.push(x[1]);\n    });\n    if (typeof line != \"string\") line = lineData.values.join(\"\");\n    var tokens = tokenizer.getLineTokens(line, state);\n    var values = tokens.tokens.map(function (x) {\n      return x.value;\n    });\n    var types = tokens.tokens.map(function (x) {\n      return x.type;\n    });\n    var err = testEqual([JSON.stringify(lineData.state), JSON.stringify(tokens.state), lineData.types, types, lineData.values, values]);\n\n    if (err) {\n      console.log(line);\n      throw \"error\";\n    }\n\n    state = tokens.state;\n  });\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 164,
      "endLine": 164,
      "before": "function test(startAt) {\n  var modes = fs.readdirSync(cwd).map(function (x) {\n    return (x.match(/tokens_(.*).json/) || {})[1];\n  }).filter(function (x) {\n    return !!x;\n  });\n\n  for (var i = Math.max(0, startAt || 0); i < modes.length; i++) testMode(modes[i], i);\n\n  console.log(\"\\u001b[32m\" + \"all ok\" + \"\\u001b[0m\");\n}",
      "after": "async function test(startAt) {\n  var modes = fs.readdirSync(cwd).map(function (x) {\n    return (x.match(/tokens_(.*).json/) || {})[1];\n  }).filter(function (x) {\n    return !!x;\n  });\n\n  for (var i = Math.max(0, startAt || 0); i < modes.length; i++) await testMode(modes[i], i);\n\n  console.log(\"\\u001b[32m\" + \"all ok\" + \"\\u001b[0m\");\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 241,
      "endLine": 241,
      "before": "test()",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait test()"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 248,
      "endLine": 248,
      "before": "test(parseInt(process.argv[2], 10) || 0)",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait test(parseInt(process.argv[2], 10) || 0)"
    },
    {
      "filename": "/home/osboxes/deepforge/src/visualizers/widgets/TextEditor/lib/ace/mode/_test/highlight_rules_test.js",
      "startLine": 250,
      "endLine": 250,
      "before": "testMode(arg, -1)",
      "after": "*Note*: File will be wrapped in an IIFE \n\nawait testMode(arg, -1)"
    }
  ],
  "5": [
    {
      "filename": "/home/osboxes/deepforge/test/globals.js",
      "startLine": 45,
      "endLine": 45,
      "before": "function (dir) {\n  var dirs = path.resolve(dir).split(path.sep),\n      shortDir,\n      i = 1;\n\n  while (i++ < dirs.length) {\n    shortDir = dirs.slice(0, i).join(path.sep);\n\n    if (!exists.sync(shortDir)) {\n      fs.mkdirSync(shortDir);\n    }\n  }\n}",
      "after": "async function (dir) {\n  var dirs = path.resolve(dir).split(path.sep),\n      shortDir,\n      i = 1;\n\n  while (i++ < dirs.length) {\n    shortDir = dirs.slice(0, i).join(path.sep);\n\n    if (!exists.sync(shortDir)) {\n      await fs.promises.mkdir(shortDir);\n    }\n  }\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/api/JobLogsClient.spec.js",
      "startLine": 25,
      "endLine": 25,
      "before": "function (done) {\n  testFixture.mkdir(blobDir);\n  server.start(done);\n}",
      "after": "async function (done) {\n  await testFixture.mkdir(blobDir);\n  server.start(done);\n}"
    },
    {
      "filename": "/home/osboxes/deepforge/test/unit/routers/JobLogsAPI/JobLogsAPI.spec.js",
      "startLine": 22,
      "endLine": 22,
      "before": "function (done) {\n  testFixture.mkdir(blobDir);\n  server = testFixture.WebGME.standaloneServer(gmeConfig);\n  url = [server.getUrl(), mntPt, project, branch, jobId].join('/');\n  server.start(done);\n}",
      "after": "async function (done) {\n  await testFixture.mkdir(blobDir);\n  server = testFixture.WebGME.standaloneServer(gmeConfig);\n  url = [server.getUrl(), mntPt, project, branch, jobId].join('/');\n  server.start(done);\n}"
    }
  ],
  "6": [
    {
      "filename": "/home/osboxes/deepforge/test/integration/StorageBackends.spec.js",
      "startLine": 33,
      "endLine": 33,
      "before": "async function () {\n  await server.start();\n  fs.writeFileSync(TEST_FILE_NAME, CONTENT);\n  StorageConfigs = await testFixture.getStorageConfigs();\n\n  for (const backend of storageBackends) {\n    client = await Storage.getClient(backend, logger, StorageConfigs[backend]);\n    clients[backend] = client;\n\n    const nop = () => {};\n\n    await client.deleteDir(TEST_STORAGE).catch(nop);\n  }\n}",
      "after": "async function () {\n  await server.start();\n  await fs.promises.writeFile(TEST_FILE_NAME, CONTENT);\n  StorageConfigs = await testFixture.getStorageConfigs();\n\n  for (const backend of storageBackends) {\n    client = await Storage.getClient(backend, logger, StorageConfigs[backend]);\n    clients[backend] = client;\n\n    const nop = () => {};\n\n    await client.deleteDir(TEST_STORAGE).catch(nop);\n  }\n}"
    }
  ],
  "7": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/OperationCode.spec.js",
      "startLine": 239,
      "endLine": 239,
      "before": "function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'multi-anon-results.py');\n  var example = fs.readFileSync(filePath, 'utf8');\n  operation = new OperationCode(example);\n}",
      "after": "async function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'multi-anon-results.py');\n  var example = await fs.promises.readFile(filePath, 'utf8');\n  operation = new OperationCode(example);\n}"
    }
  ],
  "8": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/OperationCode.spec.js",
      "startLine": 258,
      "endLine": 258,
      "before": "function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'no-inputs.py');\n  code = fs.readFileSync(filePath, 'utf8');\n}",
      "after": "async function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'no-inputs.py');\n  code = await fs.promises.readFile(filePath, 'utf8');\n}"
    }
  ],
  "9": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/OperationCode.spec.js",
      "startLine": 355,
      "endLine": 355,
      "before": "function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'simple.py');\n  code = fs.readFileSync(filePath, 'utf8');\n}",
      "after": "async function () {\n  var filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'simple.py');\n  code = await fs.promises.readFile(filePath, 'utf8');\n}"
    }
  ],
  "10": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/OperationCode.spec.js",
      "startLine": 486,
      "endLine": 486,
      "before": "function () {\n  let filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'example.py');\n  let code = fs.readFileSync(filePath, 'utf8');\n  operation = new OperationCode(code);\n}",
      "after": "async function () {\n  let filePath = path.join(__dirname, '..', 'test-cases', 'operations', 'example.py');\n  let code = await fs.promises.readFile(filePath, 'utf8');\n  operation = new OperationCode(code);\n}"
    }
  ],
  "11": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/OperationCode.spec.js",
      "startLine": 525,
      "endLine": 525,
      "before": "function testCase(name) {\n  const filePath = path.join(__dirname, '..', 'test-cases', 'operations', name);\n  return fs.readFileSync(filePath, 'utf8');\n}",
      "after": "async function testCase(name) {\n  const filePath = path.join(__dirname, '..', 'test-cases', 'operations', name);\n  return await fs.promises.readFile(filePath, 'utf8');\n}"
    }
  ],
  "12": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/common/viz/FigureExtractor.spec.js",
      "startLine": 52,
      "endLine": 52,
      "before": "async () => {\n  const exportedJSON = JSON.parse(JSON.stringify(await figureExtractor.extract(graphNode)));\n  const referenceJSON = JSON.parse(fs.readFileSync(REFERENCE_JSON));\n  assert.deepStrictEqual(exportedJSON, referenceJSON);\n}",
      "after": "async () => {\n  const exportedJSON = JSON.parse(JSON.stringify(await figureExtractor.extract(graphNode)));\n  const referenceJSON = JSON.parse(await fs.promises.readFile(REFERENCE_JSON));\n  assert.deepStrictEqual(exportedJSON, referenceJSON);\n}"
    }
  ],
  "13": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/plugins/ImportYaml/ImportYaml.spec.js",
      "startLine": 105,
      "endLine": 105,
      "before": "function (name, done) {\n  var manager = new PluginCliManager(null, logger, gmeConfig),\n      pluginConfig = {},\n      context = {\n    namespace: 'nn',\n    project: project,\n    branchName: 'test',\n    activeNode: ''\n  },\n      data = fs.readFileSync(path.join(YAML_DIR, name), 'utf8'),\n      ymlFile = path.join(YAML_DIR, name.replace(/lua$/, 'yml')),\n      yml = fs.readFileSync(ymlFile, 'utf8'),\n      initModels; // Load the children from the head of the 'test' branch\n\n  project.getBranchHash('test').then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    initModels = children.map(core.getPath);\n    return blobClient.putFile(name, data); // upload the file\n  }).then(hash => {\n    pluginConfig.srcHash = hash;\n    return Q.nfcall(manager.executePlugin.bind(manager), pluginName, pluginConfig, context);\n  }).then(pluginResult => {\n    expect(typeof pluginResult).to.equal('object');\n    expect(pluginResult.success).to.equal(true);\n    return project.getBranchHash('test');\n  }) // Use the check-model object to check the result models!\n  .then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    var newModel = children.find(model => initModels.indexOf(core.getPath(model)) === -1);\n    expect(initModels.length + 1).to.equal(children.length);\n    expect(!!newModel).to.equal(true); // found the new model\n\n    return core.loadChildren(newModel);\n  }).then(children => {\n    // Retrieve the id of the newly generated node\n    var map = checker.gme(children).map.to.yaml(yml);\n    expect(!!map).to.equal(true);\n  }).fail(err => {\n    throw err;\n  }).nodeify(done);\n}",
      "after": "async function (name, done) {\n  var manager = new PluginCliManager(null, logger, gmeConfig),\n      pluginConfig = {},\n      context = {\n    namespace: 'nn',\n    project: project,\n    branchName: 'test',\n    activeNode: ''\n  },\n      data = await fs.promises.readFile(path.join(YAML_DIR, name), 'utf8'),\n      ymlFile = path.join(YAML_DIR, name.replace(/lua$/, 'yml')),\n      yml = fs.readFileSync(ymlFile, 'utf8'),\n      initModels; // Load the children from the head of the 'test' branch\n\n  project.getBranchHash('test').then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    initModels = children.map(core.getPath);\n    return blobClient.putFile(name, data); // upload the file\n  }).then(hash => {\n    pluginConfig.srcHash = hash;\n    return Q.nfcall(manager.executePlugin.bind(manager), pluginName, pluginConfig, context);\n  }).then(pluginResult => {\n    expect(typeof pluginResult).to.equal('object');\n    expect(pluginResult.success).to.equal(true);\n    return project.getBranchHash('test');\n  }) // Use the check-model object to check the result models!\n  .then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    var newModel = children.find(model => initModels.indexOf(core.getPath(model)) === -1);\n    expect(initModels.length + 1).to.equal(children.length);\n    expect(!!newModel).to.equal(true); // found the new model\n\n    return core.loadChildren(newModel);\n  }).then(children => {\n    // Retrieve the id of the newly generated node\n    var map = checker.gme(children).map.to.yaml(yml);\n    expect(!!map).to.equal(true);\n  }).fail(err => {\n    throw err;\n  }).nodeify(done);\n}"
    }
  ],
  "14": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/plugins/ImportYaml/ImportYaml.spec.js",
      "startLine": 107,
      "endLine": 107,
      "before": "function (name, done) {\n  var manager = new PluginCliManager(null, logger, gmeConfig),\n      pluginConfig = {},\n      context = {\n    namespace: 'nn',\n    project: project,\n    branchName: 'test',\n    activeNode: ''\n  },\n      data = fs.readFileSync(path.join(YAML_DIR, name), 'utf8'),\n      ymlFile = path.join(YAML_DIR, name.replace(/lua$/, 'yml')),\n      yml = fs.readFileSync(ymlFile, 'utf8'),\n      initModels; // Load the children from the head of the 'test' branch\n\n  project.getBranchHash('test').then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    initModels = children.map(core.getPath);\n    return blobClient.putFile(name, data); // upload the file\n  }).then(hash => {\n    pluginConfig.srcHash = hash;\n    return Q.nfcall(manager.executePlugin.bind(manager), pluginName, pluginConfig, context);\n  }).then(pluginResult => {\n    expect(typeof pluginResult).to.equal('object');\n    expect(pluginResult.success).to.equal(true);\n    return project.getBranchHash('test');\n  }) // Use the check-model object to check the result models!\n  .then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    var newModel = children.find(model => initModels.indexOf(core.getPath(model)) === -1);\n    expect(initModels.length + 1).to.equal(children.length);\n    expect(!!newModel).to.equal(true); // found the new model\n\n    return core.loadChildren(newModel);\n  }).then(children => {\n    // Retrieve the id of the newly generated node\n    var map = checker.gme(children).map.to.yaml(yml);\n    expect(!!map).to.equal(true);\n  }).fail(err => {\n    throw err;\n  }).nodeify(done);\n}",
      "after": "async function (name, done) {\n  var manager = new PluginCliManager(null, logger, gmeConfig),\n      pluginConfig = {},\n      context = {\n    namespace: 'nn',\n    project: project,\n    branchName: 'test',\n    activeNode: ''\n  },\n      data = await fs.promises.readFile(path.join(YAML_DIR, name), 'utf8'),\n      ymlFile = path.join(YAML_DIR, name.replace(/lua$/, 'yml')),\n      yml = await fs.promises.readFile(ymlFile, 'utf8'),\n      initModels; // Load the children from the head of the 'test' branch\n\n  project.getBranchHash('test').then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    initModels = children.map(core.getPath);\n    return blobClient.putFile(name, data); // upload the file\n  }).then(hash => {\n    pluginConfig.srcHash = hash;\n    return Q.nfcall(manager.executePlugin.bind(manager), pluginName, pluginConfig, context);\n  }).then(pluginResult => {\n    expect(typeof pluginResult).to.equal('object');\n    expect(pluginResult.success).to.equal(true);\n    return project.getBranchHash('test');\n  }) // Use the check-model object to check the result models!\n  .then(function (branchHash) {\n    return Q.ninvoke(project, 'loadObject', branchHash);\n  }).then(function (commitObject) {\n    return Q.ninvoke(core, 'loadRoot', commitObject.root);\n  }).then(function (root) {\n    return core.loadChildren(root);\n  }).then(children => {\n    var newModel = children.find(model => initModels.indexOf(core.getPath(model)) === -1);\n    expect(initModels.length + 1).to.equal(children.length);\n    expect(!!newModel).to.equal(true); // found the new model\n\n    return core.loadChildren(newModel);\n  }).then(children => {\n    // Retrieve the id of the newly generated node\n    var map = checker.gme(children).map.to.yaml(yml);\n    expect(!!map).to.equal(true);\n  }).fail(err => {\n    throw err;\n  }).nodeify(done);\n}"
    }
  ],
  "15": [
    {
      "filename": "/home/osboxes/deepforge/test/unit/utils/utils.spec.js",
      "startLine": 59,
      "endLine": 59,
      "before": "function (nodePath, filename, result, done) {\n  var txt = fs.readFileSync(path.join(MODELS_DIR, filename + '.yml'), 'utf8');\n  core.loadByPath(rootNode, nodePath).then(node => {\n    return core.loadChildren(node);\n  }).then(children => {\n    var mappings = checker.yaml(txt).map.to.gme(children),\n        nodes = children.filter(child => {\n      var ptrs = core.getPointerNames(child);\n      return ptrs.indexOf('dst') + ptrs.indexOf('src') === -2;\n    });\n    assert.equal(!!mappings, result, 'mappings are ' + JSON.stringify(mappings));\n\n    if (result) {\n      assert.equal(nodes.length, Object.keys(mappings).length, `Missing mappings. Expected ${nodes.length} keys. Found ` + ` ${JSON.stringify(mappings)}`);\n    }\n  }).nodeify(done);\n}",
      "after": "async function (nodePath, filename, result, done) {\n  var txt = await fs.promises.readFile(path.join(MODELS_DIR, filename + '.yml'), 'utf8');\n  core.loadByPath(rootNode, nodePath).then(node => {\n    return core.loadChildren(node);\n  }).then(children => {\n    var mappings = checker.yaml(txt).map.to.gme(children),\n        nodes = children.filter(child => {\n      var ptrs = core.getPointerNames(child);\n      return ptrs.indexOf('dst') + ptrs.indexOf('src') === -2;\n    });\n    assert.equal(!!mappings, result, 'mappings are ' + JSON.stringify(mappings));\n\n    if (result) {\n      assert.equal(nodes.length, Object.keys(mappings).length, `Missing mappings. Expected ${nodes.length} keys. Found ` + ` ${JSON.stringify(mappings)}`);\n    }\n  }).nodeify(done);\n}"
    }
  ]
}